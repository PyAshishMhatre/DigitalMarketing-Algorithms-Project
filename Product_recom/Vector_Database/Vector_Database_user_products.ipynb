{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode -q\n",
        "!pip install --quiet -U pinecone-client"
      ],
      "metadata": {
        "id": "3F6Gzp2Dfyi_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from unidecode import unidecode\n",
        "import pinecone\n",
        "\n",
        "pinecone.init(api_key='XX', environment='XX')\n",
        "\n",
        "# Set a name for your index\n",
        "index_name = 'user-products'\n",
        "\n",
        "# Make sure service with the same name does not exist\n",
        "if index_name in pinecone.list_indexes():\n",
        "    pinecone.delete_index(index_name)\n",
        "pinecone.create_index(name=index_name, dimension=100)\n",
        "\n",
        "\n",
        "index = pinecone.Index(index_name=index_name)\n",
        "print(index)\n",
        "\n",
        "products = pd.read_csv('https://raw.githubusercontent.com/ashwinkadam/DigitalMarketing-Algorithms-Project/main/Product_recom/products.csv')\n",
        "# Get all of the items\n",
        "all_items = [str(title) for title in products['name']]\n",
        "    \n",
        "# Replace non-ASCII characters in item IDs with ASCII equivalents\n",
        "all_items_ascii = [unidecode(title) for title in all_items]\n",
        "    \n",
        "# Transform items into factors\n",
        "items_factors = np.load('user_factors.npy') #Add 'user_factors.npy' generated from model 1\n",
        "    \n",
        "# Prepare item factors for upload\n",
        "items_to_insert = list(zip(all_items_ascii, items_factors[1:].tolist()))\n"
      ],
      "metadata": {
        "id": "LDowcvjZzSPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunks(iterable, batch_size=100):\n",
        "    it = iter(iterable)\n",
        "    chunk = tuple(itertools.islice(it, batch_size))\n",
        "    while chunk:\n",
        "        yield chunk\n",
        "        chunk = tuple(itertools.islice(it, batch_size))\n",
        "\n",
        "print('Index statistics before upsert:', index.describe_index_stats())\n",
        "\n",
        "for e, batch in enumerate(chunks([(ii[:64],x) for ii,x in items_to_insert])):index.upsert(vectors=batch)\n",
        "\n",
        "print('Index statistics after upsert:', index.describe_index_stats())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y86nl7H-1-bU",
        "outputId": "e583159a-eb6b-438c-9473-e7ea75301922"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index statistics before upsert: {'dimension': 100,\n",
            " 'index_fullness': 0.0,\n",
            " 'namespaces': {},\n",
            " 'total_vector_count': 0}\n",
            "Index statistics after upsert: {'dimension': 100,\n",
            " 'index_fullness': 0.0,\n",
            " 'namespaces': {'': {'vector_count': 27221}},\n",
            " 'total_vector_count': 27221}\n"
          ]
        }
      ]
    }
  ]
}