{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjUgeFXRYTl0cxJTaT2/ej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyAshishMhatre/DigitalMarketing-Algorithms-Project/blob/main/QA_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Youtube video transcription"
      ],
      "metadata": {
        "id": "nIILJF_gJlmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Libraries\n",
        "!pip install pytube -q\n",
        "!pip install git+https://github.com/openai/whisper.git -"
      ],
      "metadata": {
        "id": "2vmhb5xbNkS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules for transcriptions\n",
        "\n",
        "from pytube import YouTube\n",
        "import whisper\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "djaTgz__Nj7t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "xp99kaHxIIFd"
      },
      "outputs": [],
      "source": [
        "model = whisper.load_model('tiny')\n",
        "\n",
        "# Function to download video and get transcriptions\n",
        "def get_transcriptions(url, model):\n",
        "    yt_video = YouTube(url)\n",
        "    stream = yt_video.streams.filter(only_audio=True)\n",
        "    stream = stream.first()\n",
        "    stream.download(filename=\"test.mp4\")\n",
        "    output = model.transcribe(\"test.mp4\")\n",
        "\n",
        "    filename = \"test.txt\" # the name of the file to be saved\n",
        "\n",
        "    with open(filename, \"w\") as file:\n",
        "      file.write(output[\"text\"])\n",
        "    return "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List down the youtube videos for transcription\n",
        "\n",
        "video_urls = [\"https://www.youtube.com/watch?v=blbvVUxD41Q&ab_channel=Locust%26WildHoney\",\n",
        "              \"https://www.youtube.com/watch?v=9hktZEc3Vhs&ab_channel=STYLEDBYNATE\",\n",
        "              \"https://www.youtube.com/watch?v=C9nVeYwS_8E&ab_channel=Men%27sFashionFiles\",\n",
        "              \"https://www.youtube.com/watch?v=7fJcrPjAa1I&ab_channel=UniqloReviews\",\n",
        "              \"https://www.youtube.com/watch?v=YtjHtPySBAA&ab_channel=HarryHas\"]\n",
        "\n",
        "# Loop through each video URL and get transcriptions\n",
        "for url in tqdm(video_urls):\n",
        "  get_transcriptions(url, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rupXLnvIjjg",
        "outputId": "390a0fb3-a1a6-4bb3-8157-7ffa9afe1f7d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "100%|██████████| 1/1 [01:19<00:00, 79.16s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Developing QA system using Augmented Retrival and prompt engineering using Langchain and ChromaDB (Vector Database)"
      ],
      "metadata": {
        "id": "CppEVRm-JZgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "W0JFXLnLR3iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import langchain modules \n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from typing import List\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "import os\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "22F3YU68NYM0"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup OpenAI\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"\""
      ],
      "metadata": {
        "id": "Kh5qbOFBSHhF"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load text files of transcription from directory \n",
        "\n",
        "loader = DirectoryLoader('./Document', glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True)"
      ],
      "metadata": {
        "id": "2OhteJdfgGNr"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load usind load()\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTlI57y1gZS3",
        "outputId": "5088dafc-29a6-407d-a29a-a3dcdfd322de"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 5367.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking length of loaded files\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0M98EqxgcfV",
        "outputId": "8d8040f9-47b9-4372-b002-577f2247b717"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text into small chunks for more efficient context retrival\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "_SbspdJWgdWN"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the new document length after text splitting\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZJ2ZID_Kwtp",
        "outputId": "e2a63759-6d15-493a-e772-b867ea98c147"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "771"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading vectors into Chroma DB\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwUQa-TAh0vx",
        "outputId": "8b555763-355b-4e1f-816c-29cb695afd20"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.3, openai_api_key=\"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\")"
      ],
      "metadata": {
        "id": "qpfwhfX9xT62"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the quality of tshirt?\""
      ],
      "metadata": {
        "id": "KWFSb85Jzohy"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = vectordb.similarity_search(query, k=8)"
      ],
      "metadata": {
        "id": "Z122uh-IwkZd"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dkbl6YpNEB9",
        "outputId": "640686bb-869b-49a9-a0c7-e7ba975ccb46"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"t-shirts have been very, very durable in the wash so that's definitely something. A worth mentioning\", metadata={'source': 'Document/test.txt'}),\n",
              " Document(page_content=\"improved on the T-shirt, but it wasn't back to the standards that it used to be before they changed\", metadata={'source': 'Document/Is UNIQLO Still The Best For Affordable Basics?.txt'}),\n",
              " Document(page_content=\"improved on the T-shirt, but it wasn't back to the standards that it used to be before they changed\", metadata={'source': 'Document/test4.txt'}),\n",
              " Document(page_content=\"they're any good, just want to mention some points about these shirts and my experience with them.\", metadata={'source': 'Document/Are Uniqlo shirts any good? Owner’s review.txt'}),\n",
              " Document(page_content='still sell the best quality affordable basics, or are you better off spending your money elsewhere?', metadata={'source': 'Document/Is UNIQLO Still The Best For Affordable Basics?.txt'}),\n",
              " Document(page_content='still sell the best quality affordable basics, or are you better off spending your money elsewhere?', metadata={'source': 'Document/test4.txt'}),\n",
              " Document(page_content='very soft and the material quality is very good. I wore this shirt maybe like a few times, maybe', metadata={'source': 'Document/Are Uniqlo shirts any good? Owner’s review.txt'}),\n",
              " Document(page_content='bit different in materials because this one was kind the regular linen shirt. Kind of cheaper', metadata={'source': 'Document/Are Uniqlo shirts any good? Owner’s review.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = \"\"\" Prompt: Use the following pieces of context to answer the question at the end and Answer as if your a salesman of the company\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "LCOIy3PH0f7L"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.llm import LLMChain\n",
        "chain = LLMChain(llm = llm, prompt=PROMPT)"
      ],
      "metadata": {
        "id": "19H6qR3T6sPH"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_chain = LLMChain(llm=llm, prompt=PROMPT)"
      ],
      "metadata": {
        "id": "ygki4KggHHfH"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_chain.run({'context':docsearch, 'question':query})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zJsXBEF0O3_d",
        "outputId": "6d31a543-d684-4f6f-fc0d-b599d6f80272"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Our t-shirts are very durable in the wash and have improved from their previous standards. They are very soft and the material quality is very good.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phiPue__O6fY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}